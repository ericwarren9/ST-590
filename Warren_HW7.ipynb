{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUq6uFqpZZ/IsNaSgXfBdz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericwarren9/ST-590/blob/main/Warren_HW7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ST 590 Homework 7 By: Eric Warren"
      ],
      "metadata": {
        "id": "5k4mUgZMMX0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I am going to suppress warnings so it is easier to follow along."
      ],
      "metadata": {
        "id": "QzhPM7vD0KHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "bkAdN6VI0NFk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in and Combine Data"
      ],
      "metadata": {
        "id": "lW9Uj2rIMbuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Read in the `winequality-red.csv` and `winequality-white.csv` files available on the UCI machine learning repository site.\n",
        "- Combine these two datasets and create a new variable that represents the type of wine (red or white)"
      ],
      "metadata": {
        "id": "Np7pqGI1fYsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Read in the red wine data\n",
        "red_wine = pd.read_csv(\"winequality-red.csv\", sep = \";\")\n",
        "red_wine['color_white'] = 0\n",
        "\n",
        "# Read in the white wine data\n",
        "white_wine = pd.read_csv(\"winequality-white.csv\", sep = \";\")\n",
        "white_wine['color_white'] = 1\n",
        "\n",
        "# Combine the data into one data frame\n",
        "wine = red_wine.append(white_wine)\n",
        "wine # Show our combined data frame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "7_wMS-qbfhl7",
        "outputId": "ea26d00e-e70b-4c2b-d2da-f2c2772bbb78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4              0.70         0.00             1.9      0.076   \n",
              "1               7.8              0.88         0.00             2.6      0.098   \n",
              "2               7.8              0.76         0.04             2.3      0.092   \n",
              "3              11.2              0.28         0.56             1.9      0.075   \n",
              "4               7.4              0.70         0.00             1.9      0.076   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "4893            6.2              0.21         0.29             1.6      0.039   \n",
              "4894            6.6              0.32         0.36             8.0      0.047   \n",
              "4895            6.5              0.24         0.19             1.2      0.041   \n",
              "4896            5.5              0.29         0.30             1.1      0.022   \n",
              "4897            6.0              0.21         0.38             0.8      0.020   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
              "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
              "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
              "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
              "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
              "\n",
              "      alcohol  quality  color_white  \n",
              "0         9.4        5            0  \n",
              "1         9.8        5            0  \n",
              "2         9.8        5            0  \n",
              "3         9.8        6            0  \n",
              "4         9.4        5            0  \n",
              "...       ...      ...          ...  \n",
              "4893     11.2        6            1  \n",
              "4894      9.6        5            1  \n",
              "4895      9.4        6            1  \n",
              "4896     12.8        7            1  \n",
              "4897     11.8        6            1  \n",
              "\n",
              "[6497 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e666102c-ac3a-47c4-ae45-b66faa68d8a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>color_white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4893</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4895</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e666102c-ac3a-47c4-ae45-b66faa68d8a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e666102c-ac3a-47c4-ae45-b66faa68d8a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e666102c-ac3a-47c4-ae45-b66faa68d8a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6543fa82-c8b0-4e6d-a2c3-b3bd9edae5bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6543fa82-c8b0-4e6d-a2c3-b3bd9edae5bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6543fa82-c8b0-4e6d-a2c3-b3bd9edae5bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "wine",
              "summary": "{\n  \"name\": \"wine\",\n  \"rows\": 6497,\n  \"fields\": [\n    {\n      \"column\": \"fixed acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2964337577998153,\n        \"min\": 3.8,\n        \"max\": 15.9,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          7.15,\n          8.1,\n          7.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatile acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16463647408467877,\n        \"min\": 0.08,\n        \"max\": 1.58,\n        \"num_unique_values\": 187,\n        \"samples\": [\n          0.405,\n          0.21,\n          0.695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"citric acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14531786489759155,\n        \"min\": 0.0,\n        \"max\": 1.66,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.1,\n          0.6,\n          0.37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"residual sugar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.757803743147418,\n        \"min\": 0.6,\n        \"max\": 65.8,\n        \"num_unique_values\": 316,\n        \"samples\": [\n          18.95,\n          3.2,\n          9.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chlorides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03503360137245907,\n        \"min\": 0.009,\n        \"max\": 0.611,\n        \"num_unique_values\": 214,\n        \"samples\": [\n          0.089,\n          0.217,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"free sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.7493997720025,\n        \"min\": 1.0,\n        \"max\": 289.0,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          77.5,\n          65.0,\n          128.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56.521854522630285,\n        \"min\": 6.0,\n        \"max\": 440.0,\n        \"num_unique_values\": 276,\n        \"samples\": [\n          14.0,\n          149.0,\n          227.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0029986730037190393,\n        \"min\": 0.98711,\n        \"max\": 1.03898,\n        \"num_unique_values\": 998,\n        \"samples\": [\n          0.9918,\n          0.99412,\n          0.99484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16078720210398764,\n        \"min\": 2.72,\n        \"max\": 4.01,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          3.74,\n          3.17,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sulphates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14880587361449027,\n        \"min\": 0.22,\n        \"max\": 2.0,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          1.11,\n          1.56,\n          0.46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.192711748870993,\n        \"min\": 8.0,\n        \"max\": 14.9,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          10.9333333333333,\n          9.7,\n          10.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5,\n          6,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"color_white\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Data"
      ],
      "metadata": {
        "id": "wR5WcjE0gy3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split up the data set into a training and test set. For this, I want you to use stratified sampling to\n",
        "make sure that you have a similar proportion of white and red wines in the training and test sets. This\n",
        "can be done with the `train_test_split()` function."
      ],
      "metadata": {
        "id": "LeM-d9M-g0d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import needed functions for modeling\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, Lasso, Ridge, RidgeCV, ElasticNet, ElasticNetCV, LogisticRegression, LogisticRegressionCV\n",
        "\n",
        "# Split the data in a way that the proportion of red and white wine is same\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine.drop(\"alcohol\", axis = 1),\n",
        "    wine[\"alcohol\"],\n",
        "    test_size = 0.20,\n",
        "    random_state = 99,\n",
        "    stratify = wine['color_white'])"
      ],
      "metadata": {
        "id": "XZo-21D9g-DK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Task (alcohol as Response)"
      ],
      "metadata": {
        "id": "OQGLxz18j0Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Models"
      ],
      "metadata": {
        "id": "cRFBIG_Jj4xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit four different multiple linear regression models.\n",
        "\n",
        "- At least one should include interaction terms\n",
        "- At least one should include some polynomial terms\n",
        "- Use CV to select your best MLR model"
      ],
      "metadata": {
        "id": "R9NHceOcj-iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow us to use interaction terms and numpy\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Make a full MLR model\n",
        "mlr1 = cross_validate(\n",
        "    LinearRegression(),\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_mean_squared_error\")\n",
        "\n",
        "# Make a MLR model with only the pH, sulphates, quality, and color_white\n",
        "mlr2 = cross_validate(\n",
        "    LinearRegression(),\n",
        "    X_train[[\"pH\", \"sulphates\", \"quality\", \"color_white\"]],\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_mean_squared_error\")\n",
        "\n",
        "# Make a MLR model with the interaction terms for all of the columns we selected above\n",
        "poly = PolynomialFeatures(interaction_only = True, include_bias = False)\n",
        "X_design = poly.fit_transform(X_train[[\"pH\", \"sulphates\", \"quality\", \"color_white\"]])\n",
        "mlr3 = cross_validate(\n",
        "    LinearRegression(),\n",
        "    X_design,\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_mean_squared_error\")\n",
        "\n",
        "# Make a MLR model that includes a quadratic term for our columns\n",
        "poly2 = PolynomialFeatures(degree = 2, interaction_only = False, include_bias = False)\n",
        "X_design2 = poly2.fit_transform(X_train[[\"pH\", \"sulphates\", \"quality\", \"color_white\"]])\n",
        "mlr4 = cross_validate(\n",
        "    LinearRegression(),\n",
        "    X_design2,\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_mean_squared_error\")\n",
        "\n",
        "# Print which model has the best CV error and select that model to test in future\n",
        "print(np.sqrt(-sum(mlr1['test_score'])),\n",
        "      np.sqrt(-sum(mlr2['test_score'])),\n",
        "      np.sqrt(-sum(mlr3['test_score'])),\n",
        "      np.sqrt(-sum(mlr4['test_score'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN3h_pMXkIz0",
        "outputId": "be879d22-00f5-4c3d-b419-bdf9c6666f6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0333519118768444 2.3530136757851543 2.348408083800981 2.3302342552083974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see here our first model, which is just putting in a regular full model is the best. Let us save this best model to test for later."
      ],
      "metadata": {
        "id": "aR5ZgQeGqbY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlr_best = LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nrbK0q2qqwOZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to fit a LASSO model with a set of predictors of our choosing\n",
        "\n",
        "- Use at least five predictors\n",
        "- Use CV to select the tuning parameter\n",
        "\n",
        "Then we are going to fit the model with the best tuning paramter to use for testing for later."
      ],
      "metadata": {
        "id": "cnaW4b3sqgC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit our lasso model to get the best tuning parameter\n",
        "lasso_mod = LassoCV(cv = 5, random_state = 99).fit(X_train, y_train)\n",
        "\n",
        "# Print the best alpha tuning parameter\n",
        "print(lasso_mod.alpha_)\n",
        "\n",
        "# Fit our best model\n",
        "lasso_best = Lasso(lasso_mod.alpha_).fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_tAclYBqo1u",
        "outputId": "98d0ad32-5458-4cd9-977c-ea0a7594c960"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.017540010541499004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that our best tuning parameter is quite small (and not far off from 0 saying the same as a MLR model)."
      ],
      "metadata": {
        "id": "GMaSP33Lrjv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to fit a Ridge Regression model with a set of predictors of our choosing\n",
        "\n",
        "- Use at least five predictors\n",
        "- Use CV to select the tuning parameter\n",
        "\n",
        "Then we are going to fit our model with the best tuning paramter to use for testing for later."
      ],
      "metadata": {
        "id": "UfbVqwnerubi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit our ridge model to get the best tuning parameter\n",
        "ridge_mod = RidgeCV(cv = 5,\n",
        "                    alphas=[0.0001, 0.001, 0.01, 0.02, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 0.9, 0.93, 0.95, 0.97, 0.98, 0.99, 1]).fit(X_train, y_train)\n",
        "\n",
        "# Print the best alpha tuning parameter\n",
        "print(ridge_mod.alpha_)\n",
        "\n",
        "# Fit our best model\n",
        "ridge_best = Ridge(ridge_mod.alpha_).fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2L4vPFTr-93",
        "outputId": "b936444e-25b2-4b29-f3ef-9970e59fd36a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again we can see a small penalty term applied to our ridge model, which is something to note that not much penalty is applied and makes it similar to a MLR model."
      ],
      "metadata": {
        "id": "_rimQHTutnVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we are going to fit an Elastic Net model with a set of predictors of your choosing\n",
        "\n",
        "- Use at least five predictors\n",
        "- Use CV to select the tuning parameters\n",
        "\n",
        "Then we are going to fit our model with the best tuning paramter to use for testing for later."
      ],
      "metadata": {
        "id": "z7-UznmEuKP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit our elastic net model to get the best tuning parameters\n",
        "regr = ElasticNetCV(cv = 5,\n",
        "                    random_state = 99,\n",
        "                    l1_ratio = [0.0001, 0.001, 0.01, 0.02, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.96, 0.98, 0.99, 1],\n",
        "                    n_alphas = 50)\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "# Print the best alpha parameter\n",
        "print(regr.alpha_)\n",
        "\n",
        "# Print the best ratio parameter\n",
        "print(regr.l1_ratio_)\n",
        "\n",
        "# Fit our best elastic net model\n",
        "en_best = ElasticNet(alpha = regr.alpha_, l1_ratio = regr.l1_ratio_).fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBJMTwLqub5m",
        "outputId": "01ef331c-935c-40ba-bba3-9524becea5cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.017540010541499004\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now got our best alpha which is small like our LASSO model and then a high ratio used as our second tuning paramter which is showing that our best elastic net model is just using our LASSO model."
      ],
      "metadata": {
        "id": "kNgqDc-_vlIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Models"
      ],
      "metadata": {
        "id": "lDkJd4J9vzC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using your four selected models, compare their performance on the test set.\n",
        "\n",
        "- Do so using RMSE as your model metric\n",
        "- Do so using MAE as your model metric"
      ],
      "metadata": {
        "id": "36oTlJzKv2UQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First look at using RMSE as our model metric."
      ],
      "metadata": {
        "id": "Ry2cI4Myv-3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get our predictions from our model using our test set\n",
        "mlr_pred = mlr_best.predict(X_test)\n",
        "lasso_pred = lasso_best.predict(X_test)\n",
        "ridge_pred = ridge_best.predict(X_test)\n",
        "en_pred = en_best.predict(X_test)\n",
        "\n",
        "# Get our RMSE values to see which has the lowest test value\n",
        "print(np.sqrt(mean_squared_error(y_test, mlr_pred)),\n",
        "      np.sqrt(mean_squared_error(y_test, lasso_pred)),\n",
        "      np.sqrt(mean_squared_error(y_test, ridge_pred)),\n",
        "      np.sqrt(mean_squared_error(y_test, en_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpRISD1RwFD0",
        "outputId": "3f8631a2-a49e-49ec-abf4-bc62eec6f22c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6323347806538819 0.9921748582591342 0.6299583102758477 0.9921748582591342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see our Ridge Regression model does the best in terms of looking at RMSE, which makes us believe this could be the best model to use."
      ],
      "metadata": {
        "id": "lUDSYmBjwjEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next look at using MAE as our model metric."
      ],
      "metadata": {
        "id": "qV4IyVPbwBpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get our MAE values to see which has the lowest test value\n",
        "print(mean_absolute_error(y_test, mlr_pred),\n",
        "      mean_absolute_error(y_test, lasso_pred),\n",
        "      mean_absolute_error(y_test, ridge_pred),\n",
        "      mean_absolute_error(y_test, en_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0MxDLJPwr8x",
        "outputId": "41137434-f36a-49ee-c6d0-783a10ab7ef7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.34808428128412455 0.7894563357522837 0.3496689651462296 0.7894563357522837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case the MLR full model does just better than our Ridge Regression Model."
      ],
      "metadata": {
        "id": "sTpYCxfOxDH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the Ridge and Multiple Linear Regression models both performing about the same in terms of test errors, I would say either model is perfectly sufficient to use. Note that our penality term for Ridge Regression was quite small, showing the results to Ridge and MLR were going to be roughly the same. Due to the ability of interpretability, I would use the MLR model since we usually want to only sacrifice this if something else is better, which isn't really the case here. Also note that LASSO (and elastic net) really do not perform as well as Ridge and MLR."
      ],
      "metadata": {
        "id": "Y85vBZJ7xIUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Task (Wine Type as Response)"
      ],
      "metadata": {
        "id": "i_Dhmqp0xsXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Repeat the training and testing done previously but use logistic regression models.\n",
        "- Use log-loss or negative log-loss as your metric for choosing models during the training process\n",
        "- During the testing portion, compare your models on both log-loss and accuracy"
      ],
      "metadata": {
        "id": "ek1ZC1bexv1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the Data Again"
      ],
      "metadata": {
        "id": "xmt5pRDOyeft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we are going to split our data with now our response being the wine type (really the color of the wine)."
      ],
      "metadata": {
        "id": "DkGcLHlCx9Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data in a way that the proportion of red and white wine is same\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine.drop(\"color_white\", axis = 1),\n",
        "    wine[\"color_white\"],\n",
        "    test_size = 0.20,\n",
        "    random_state = 99,\n",
        "    stratify = wine['color_white'])"
      ],
      "metadata": {
        "id": "z_ol_gL_yCiS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Different Models"
      ],
      "metadata": {
        "id": "0AKcWJU0yg0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit four different logistic regression models.\n",
        "\n",
        "- At least one should include interaction terms\n",
        "- At least one should include some polynomial terms\n",
        "- Use CV to select your best logistic regression model"
      ],
      "metadata": {
        "id": "t2vWLKTlyNMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a full logistic regression model\n",
        "log_reg1 = cross_validate(\n",
        "    LogisticRegression(penalty = 'none', solver = \"newton-cg\"),\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_log_loss\")\n",
        "\n",
        "# Fit a logistic regression model with pH, sulfates, alcohol, and quality\n",
        "log_reg2 = cross_validate(\n",
        "    LogisticRegression(penalty = 'none', solver = \"newton-cg\"),\n",
        "    X_train[[\"pH\", \"sulphates\", \"quality\", \"alcohol\"]],\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_log_loss\")\n",
        "\n",
        "# Make a MLR model with the interaction terms for all of the columns we selected above\n",
        "poly = PolynomialFeatures(interaction_only = True, include_bias = False)\n",
        "X_design = poly.fit_transform(X_train[[\"pH\", \"sulphates\", \"quality\", \"alcohol\"]])\n",
        "log_reg3 = cross_validate(\n",
        "    LogisticRegression(penalty = 'none', solver = \"newton-cg\"),\n",
        "    X_design,\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_mean_squared_error\")\n",
        "\n",
        "# Make a MLR model that includes a quadratic term for our columns\n",
        "poly2 = PolynomialFeatures(degree = 2, interaction_only = False, include_bias = False)\n",
        "X_design2 = poly2.fit_transform(X_train[[\"pH\", \"sulphates\", \"quality\", \"alcohol\"]])\n",
        "log_reg4 = cross_validate(\n",
        "    LogisticRegression(penalty = 'none', solver = \"newton-cg\"),\n",
        "    X_design2,\n",
        "    y_train,\n",
        "    cv = 5,\n",
        "    scoring = \"neg_mean_squared_error\")\n",
        "\n",
        "# Print which model has the best CV error and select that model to test in future\n",
        "print(round(log_reg1['test_score'].mean(), 4),\n",
        "      round(log_reg2['test_score'].mean(), 4),\n",
        "      round(log_reg3['test_score'].mean(), 4),\n",
        "      round(log_reg4['test_score'].mean(), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aeg1_lfYyo0U",
        "outputId": "18b5196c-3051-4ab9-a4b3-212c7dc8db1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0334 -0.3823 -0.178 -0.1738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here again our full model is by far the best so we are going to use that for our future logistic regression candidate model for the \"regular\" approach we are used to."
      ],
      "metadata": {
        "id": "C7uIvJRI11vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_log_best = LogisticRegression(penalty = 'none', solver = \"newton-cg\").fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ok88TGCC2BGr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to fit a logistic regression LASSO model with a set of predictors of our choosing (this is only using our l1_ratio here)\n",
        "\n",
        "- Use at least five predictors\n",
        "- Use CV to select the tuning parameter\n",
        "\n",
        "Then we are going to fit the model with the best tuning paramter to use for testing for later."
      ],
      "metadata": {
        "id": "mct8kEW62NBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the cross validation to find the best tuning parameter\n",
        "lasso_log_cv = LogisticRegressionCV(cv = 5,\n",
        "                                    solver = \"saga\",\n",
        "                                    penalty = \"l1\",\n",
        "                                    Cs = 25,\n",
        "                                    scoring = \"neg_log_loss\",\n",
        "                                    random_state = 99)\n",
        "lasso_log_cv.fit(X_train, y_train)\n",
        "\n",
        "# Show the regularization value\n",
        "print(lasso_log_cv.C_)\n",
        "\n",
        "# Now fit our best model\n",
        "lasso_best_log = LogisticRegression(solver = \"saga\",\n",
        "                                    penalty = \"l1\",\n",
        "                                    C = lasso_log_cv.C_[0],\n",
        "                                    random_state = 99)\n",
        "lasso_best_log.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "HW1l3XTV2VpA",
        "outputId": "24dab875-67f5-45c7-d92c-a663a68b77d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10000.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000.0, penalty='l1', random_state=99, solver='saga')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000.0, penalty=&#x27;l1&#x27;, random_state=99, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10000.0, penalty=&#x27;l1&#x27;, random_state=99, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the high value which means it is not really regularized. Just something to note meaning this might not be the best procedure."
      ],
      "metadata": {
        "id": "sLzo2yBf6389"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to fit a logistic regression ridge model with a set of predictors of our choosing (this is only using our l2_ratio here)\n",
        "\n",
        "- Use at least five predictors\n",
        "- Use CV to select the tuning parameter\n",
        "\n",
        "Then we are going to fit the model with the best tuning paramter to use for testing for later."
      ],
      "metadata": {
        "id": "8dtuKtpn7C-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the cross validation to find the best tuning parameter\n",
        "ridge_log_cv = LogisticRegressionCV(cv = 5,\n",
        "                                    solver = \"newton-cg\",\n",
        "                                    penalty = \"l2\",\n",
        "                                    Cs = 25,\n",
        "                                    scoring = \"neg_log_loss\",\n",
        "                                    random_state = 99)\n",
        "ridge_log_cv.fit(X_train, y_train)\n",
        "\n",
        "# Show the regularization value\n",
        "print(ridge_log_cv.C_)\n",
        "\n",
        "# Now fit our best model\n",
        "ridge_best_log = LogisticRegression(solver = \"newton-cg\",\n",
        "                                    penalty = \"l2\",\n",
        "                                    C = ridge_log_cv.C_[0],\n",
        "                                    random_state = 99)\n",
        "ridge_best_log.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "lrWc5abl7Hwl",
        "outputId": "435c07ea-9fef-4463-f8d0-8590eb2df302"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10000.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000.0, random_state=99, solver='newton-cg')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000.0, random_state=99, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10000.0, random_state=99, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the high value which means it is not really regularized. Just something to note meaning this might not be the best procedure."
      ],
      "metadata": {
        "id": "eAKvRqA87XqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we are going to fit a logistic regression elastic net model with a set of predictors of our choosing (this is only using our l1_ratio and l2_ratio here and having to specify l1_weight)\n",
        "\n",
        "- Use at least five predictors\n",
        "- Use CV to select the tuning parameter\n",
        "\n",
        "Then we are going to fit the model with the best tuning paramter to use for testing for later."
      ],
      "metadata": {
        "id": "FXUsuBPs7Y9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the cross validation to find the best tuning parameter\n",
        "e_net_log_cv = LogisticRegressionCV(cv = 5,\n",
        "                                    solver = \"saga\",\n",
        "                                    penalty = \"elasticnet\",\n",
        "                                    Cs = 10,\n",
        "                                    l1_ratios = [0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99],\n",
        "                                    scoring = \"neg_log_loss\",\n",
        "                                    random_state = 99)\n",
        "e_net_log_cv.fit(X_train, y_train)\n",
        "\n",
        "# Show the regularization value\n",
        "print(e_net_log_cv.C_)\n",
        "print(e_net_log_cv.l1_ratio_)\n",
        "\n",
        "# Now fit our best model\n",
        "e_net_best_log = LogisticRegression(solver = \"saga\",\n",
        "                                    penalty = \"elasticnet\",\n",
        "                                    C = e_net_log_cv.C_[0],\n",
        "                                    l1_ratio = e_net_log_cv.l1_ratio_[0],\n",
        "                                    random_state = 99)\n",
        "e_net_best_log.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "0YtZcfc47nPa",
        "outputId": "10a5375a-d34c-437f-d6dc-6c135790e3f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10000.]\n",
            "[0.001]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000.0, l1_ratio=0.001, penalty='elasticnet',\n",
              "                   random_state=99, solver='saga')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000.0, l1_ratio=0.001, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=99, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10000.0, l1_ratio=0.001, penalty=&#x27;elasticnet&#x27;,\n",
              "                   random_state=99, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the high value which means it is not really regularized. Just something to note meaning this might not be the best procedure. Also note the low l1_ratio. This is showing how we are not really using our l1 (or lasso component) that much to make an optimal model and similar to our l2 (or ridge) model."
      ],
      "metadata": {
        "id": "Ybhg0sFZ-ads"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Logistic Models"
      ],
      "metadata": {
        "id": "vALGBGyO-qiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using your four selected models, compare their performance on the test set.\n",
        "\n",
        "- Do so using log-loss as your model metric\n",
        "- Do so using accuracy as your model metric\n",
        "\n"
      ],
      "metadata": {
        "id": "0Jt54Vp5-u1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will check using log-loss as our metric."
      ],
      "metadata": {
        "id": "-_9Cr85NAK2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our metrics\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "\n",
        "# Get our predictions from our model using our test set\n",
        "reg_pred = reg_log_best.predict(X_test)\n",
        "lasso_pred = lasso_best_log.predict(X_test)\n",
        "ridge_pred = ridge_best_log.predict(X_test)\n",
        "en_pred = e_net_best_log.predict(X_test)\n",
        "\n",
        "# Get our log-loss values to see which has the lowest test value\n",
        "print(log_loss(y_test, reg_pred),\n",
        "      log_loss(y_test, lasso_pred),\n",
        "      log_loss(y_test, ridge_pred),\n",
        "      log_loss(y_test, en_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diIx3wmq_Pd_",
        "outputId": "bd2f8d48-50d8-4497-92e1-e15bf0403d53"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1940812105567849 1.8576344439006534 0.2495329850015805 1.8576344439006534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see how our regular (no penalty term) logistic regression model had the lowest log-loss, which makes us think it did the best. We will check with the accuracy as well."
      ],
      "metadata": {
        "id": "7S03GEOBAA0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get our accuracy values to see which has the lowest test value\n",
        "print(accuracy_score(y_test, reg_pred),\n",
        "      accuracy_score(y_test, lasso_pred),\n",
        "      accuracy_score(y_test, ridge_pred),\n",
        "      accuracy_score(y_test, en_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTLAm6bDAOdV",
        "outputId": "eb79d6e4-2172-4a60-de9f-eaa61a2fd670"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9946153846153846 0.9484615384615385 0.9930769230769231 0.9484615384615385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see how our regular (no penalty term) logistic regression model had the highest accuracy, which makes us say that it is the best model to use coupled with the log-loss results. Therefore, for our logistic regression case we should just a logistic regression model with no penalty terms."
      ],
      "metadata": {
        "id": "ITZkFgFGAYLw"
      }
    }
  ]
}